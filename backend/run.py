import os
import time
from datetime import datetime
from dotenv import load_dotenv

# Import all the modules you need
from app.database import connect_to_db, create_database, create_tables, clear_tables
from app.ebay_search import (
    get_access_token, search_ebay_listings, get_item_details,
    CLIENT_ID, CLIENT_SECRET, TOKEN_URL, SEARCH_KEYWORDS, 
    MARKETPLACE_ID, RESULTS_PER_PAGE, MAX_PAGES, SELLER_FEEDBACK_MIN
)
from app.database import insert_data
from app.zero_shot_classifier import update_gold_column
from app.extract_metadata import extract_metadata
from app.calculate_profit import update_profit_column
from app.scam_risk_score import update_scam_risk_score_column

load_dotenv()

def log_step(step_name, start_time=None):
    """Helper function to log each step with timing"""
    current_time = datetime.now()
    if start_time:
        duration = current_time - start_time
        print(f"âœ… {step_name} completed in {duration.total_seconds():.2f} seconds")
    else:
        print(f"ğŸ”„ Starting {step_name}...")
    return current_time

def main():
    """Main pipeline function that orchestrates the entire process"""
    pipeline_start = datetime.now()
    print(f"ğŸš€ Starting eBay Gold Scraper Pipeline at {pipeline_start.strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # Define multiple search keywords
    SEARCH_KEYWORDS_LIST = [
        'scrap gold 14k',
        'scrap gold 10k', 
        'scrap gold 18k',
        'gold jewelry scrap',
        'broken gold jewelry',
        'gold estate jewelry'
    ]
    
    # Step 1: Database Setup
    step_start = log_step("Database connection and setup")
    try:
        create_database()  # Create database if it doesn't exist
        conn = connect_to_db()
        if not conn:
            raise Exception("Failed to connect to database")
        
        create_tables(conn)  # Ensure tables exist
        clear_tables(conn)   # Clear existing data
        log_step("Database setup", step_start)
    except Exception as e:
        print(f"âŒ Database setup failed: {e}")
        return False

    # Step 2: eBay API Authentication
    step_start = log_step("eBay API authentication")
    try:
        access_token = get_access_token(CLIENT_ID, CLIENT_SECRET, TOKEN_URL)
        if not access_token:
            raise Exception("Failed to get access token")
        log_step("eBay API authentication", step_start)
    except Exception as e:
        print(f"âŒ eBay API authentication failed: {e}")
        conn.close()
        return False

    # Step 3: Scrape eBay Listings with Batch Processing
    step_start = log_step("eBay listings scraping")
    try:
        # Construct search filters
        search_filters = []
        if SELLER_FEEDBACK_MIN > 0:
            search_filters.append(f"feedbackScoreMin:[{SELLER_FEEDBACK_MIN}]")
        filter_string = ",".join(search_filters) if search_filters else None

        # Batch processing configuration
        BATCH_SIZE = 100
        batch_items = []
        total_items_processed = 0
        max_items_per_keyword = 1000  # Increased for large-scale scraping

        for keyword_index, search_keyword in enumerate(SEARCH_KEYWORDS_LIST):
            print(f"\n  ğŸ” Keyword {keyword_index + 1}/{len(SEARCH_KEYWORDS_LIST)}: '{search_keyword}'")
            
            page_number = 1
            items_for_this_keyword = 0
            
            while page_number <= MAX_PAGES and items_for_this_keyword < max_items_per_keyword:
                print(f"    ğŸ“„ Processing page {page_number} for '{search_keyword}'...")
                
                # Calculate offset for pagination
                offset = (page_number - 1) * RESULTS_PER_PAGE

                item_summaries, total_listings = search_ebay_listings(
                    access_token=access_token,
                    search_query=search_keyword,
                    category_ids=None,
                    limit=RESULTS_PER_PAGE,
                    marketplace_id=MARKETPLACE_ID,
                    filter_str=filter_string,
                    offset=offset
                )

                if total_listings == 0 or not item_summaries:
                    print(f"    â„¹ï¸ No more listings found for '{search_keyword}'")
                    break

                items_processed_this_page = 0
                for summary in item_summaries:
                    if items_for_this_keyword >= max_items_per_keyword:
                        break
                        
                    item_id = summary.get('itemId')
                    
                    # Check for duplicates in database instead of memory
                    cursor = conn.cursor()
                    cursor.execute("SELECT COUNT(*) FROM ebay_listings WHERE item_id = %s", (item_id,))
                    if cursor.fetchone()[0] > 0:
                        print(f"      â­ï¸ Skipping duplicate item: {item_id}")
                        cursor.close()
                        continue
                    cursor.close()
                    
                    seller_info = summary.get('seller', {})
                    item_details = get_item_details(access_token, item_id, MARKETPLACE_ID)
                    
                    if item_details:
                        item_data = {
                            'item_id': item_id,
                            'title': summary.get('title'),
                            'price': summary.get('price', {}).get('value'),
                            'currency': summary.get('price', {}).get('currency'),
                            'seller_username': seller_info.get('username'),
                            'seller_feedback_score': seller_info.get('feedbackScore'),
                            'feedback_percent': seller_info.get('feedbackPercentage'),
                            'image_url': summary.get('image', {}).get('imageUrl'),
                            'item_url': summary.get('itemWebUrl'),
                            'shipping_options': summary.get('shippingOptions', None),
                            'top_rated_buying_experience': summary.get('topRatedBuyingExperience'),
                            'description': item_details.get('description', None),
                            'returns_accepted': item_details.get('returns_accepted', None),
                            'metal': item_details.get('metal', None),
                            'total_carat_weight': item_details.get('total_carat_weight', None),
                            'metal_purity': item_details.get('metal_purity', None),
                            'item_specifics': item_details.get('item_specifics', {}),
                            'search_keyword': search_keyword
                        }
                        
                        batch_items.append(item_data)
                        items_processed_this_page += 1
                        items_for_this_keyword += 1
                        total_items_processed += 1

                        # Process batch when it reaches BATCH_SIZE
                        if len(batch_items) >= BATCH_SIZE:
                            print(f"      ğŸ“¦ Processing batch of {len(batch_items)} items...")
                            successful_inserts = 0
                            for item in batch_items:
                                if insert_data(conn, "ebay_listings", item):
                                    successful_inserts += 1
                            print(f"      âœ… Successfully inserted {successful_inserts}/{len(batch_items)} items")
                            batch_items = []  # Clear the batch

                print(f"    ğŸ“Š Found {items_processed_this_page} new items for '{search_keyword}' on page {page_number}")
                page_number += 1
            
            print(f"    âœ… Completed '{search_keyword}': {items_for_this_keyword} items processed")

        # Process any remaining items in the final batch
        if batch_items:
            print(f"\n  ğŸ“¦ Processing final batch of {len(batch_items)} items...")
            successful_inserts = 0
            for item in batch_items:
                if insert_data(conn, "ebay_listings", item):
                    successful_inserts += 1
            print(f"  âœ… Successfully inserted {successful_inserts}/{len(batch_items)} items")

        print(f"  ğŸ“Š Total items processed: {total_items_processed}")
        log_step("eBay listings scraping (multiple keywords)", step_start)
    except Exception as e:
        print(f"âŒ eBay scraping failed: {e}")
        conn.close()
        return False

    # Step 4: Gold Classification
    step_start = log_step("Gold classification (AI)")
    try:
        update_gold_column(conn)
        log_step("Gold classification", step_start)
    except Exception as e:
        print(f"âŒ Gold classification failed: {e}")
        conn.close()
        return False

    # Step 5: Metadata Extraction
    step_start = log_step("Metadata extraction")
    try:
        extract_metadata(conn)
        log_step("Metadata extraction", step_start)
    except Exception as e:
        print(f"âŒ Metadata extraction failed: {e}")
        conn.close()
        return False

    # Step 6: Profit Calculation
    step_start = log_step("Profit calculation")
    try:
        update_profit_column(conn)
        log_step("Profit calculation", step_start)
    except Exception as e:
        print(f"âŒ Profit calculation failed: {e}")
        conn.close()
        return False

    # Step 7: Scam Risk Assessment
    step_start = log_step("Scam risk assessment (AI)")
    try:
        update_scam_risk_score_column(conn)
        log_step("Scam risk assessment", step_start)
    except Exception as e:
        print(f"âŒ Scam risk assessment failed: {e}")
        conn.close()
        return False

    # Cleanup
    conn.close()
    
    # Final Summary
    pipeline_end = datetime.now()
    total_duration = pipeline_end - pipeline_start
    print("=" * 60)
    print(f"ğŸ‰ Pipeline completed successfully!")
    print(f"â±ï¸  Total duration: {total_duration.total_seconds():.2f} seconds")
    print(f"ğŸ“Š Final stats: {total_items_processed} items processed")
    print(f"ğŸ• Finished at: {pipeline_end.strftime('%Y-%m-%d %H:%M:%S')}")
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        print("\nâŒ Pipeline failed. Check the logs above for details.")
        exit(1)
    else:
        print("\nâœ… Pipeline completed successfully!")
        exit(0)